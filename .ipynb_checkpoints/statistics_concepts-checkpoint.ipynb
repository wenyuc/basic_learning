{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 概率与统计\n",
    "\n",
    "概率（Probability）研究的问题是，已知一个模型和参数，怎么去预测这个模型产生的结果的特性（例如均值，方差，协方差等等）。 \n",
    "> 举个例子，我想研究怎么养跑山猪（**模型是跑山猪**），我选好了想养的品种、喂养方式、喂养地点、猪棚的设计等等（**选择参数**），我想知道我养出来的猪的出栏率，多重，肉质怎么样（**预测结果**）。\n",
    "\n",
    "统计（statistics）研究的问题正好相反。统计问题是，有一堆数据，要利用这堆数据去预测模型和参数。\n",
    "> 仍以猪为例。现在我买到了一堆肉，通过观察和判断，我确定这是跑山猪肉（这就**确定了模型**。在实际研究中，也是通过观察数据推测模型是／像高斯分布的、指数分布的、拉普拉斯分布的等等），然后，可以进一步研究，判定这猪的品种、这是喂养方式，等等（**推测模型参数**）。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 极大似然估计(Maximum Likilihood Estimation, ELM)与贝叶斯估计(Bayseian Estimation)\n",
    "\n",
    "#### 极大似然估计 MLE\n",
    "极大似然估计，通俗理解来说，**就是利用已知的样本的结果信息，反推最具有可能（最大概率）导致这些样本结果出现的模型参数值**。\n",
    "\n",
    "**换句话说，极大似然估计提供了一种给定观察数据来评估模型参数的方法，即：“模型已定，参数未知”。\n",
    "\n",
    "比如正态分布中公式如下：\n",
    "\n",
    "如果我通过极大似然估计，得到模型中参数u和sigma的值，那么这个模型的均值和方差以及其他所有的信息我们是不是就知道了呢？确实是这样的。\n",
    "\n",
    "**极大似然估计中采样需要满足一个重要的假设，就是所有的采用都是独立同分布的。**\n",
    "\n",
    "首先看一下似然函数p(x|theta) 的理解：\n",
    "输入有两个：x表示一个具体的数据；theta表示模型的参数。\n",
    "\n",
    "如果theta是已知确定的，x是变量，这个函数叫做**概率函数（probability function），它描述对于不同的样本点x，其出现的概率是多少。**\n",
    "如果x是已知的，theta是变量，这个函数叫做**似然函数（likelihood function），它描述对于不同的模型参数，出现x这个样本点的概率是多少。**\n",
    "\n",
    "##### MLE例子\n",
    "\n",
    "假如有一个罐子，里面有黑白两种颜色的球，数目多少不知，两种颜色的比例也不知。我 们想知道罐中白球和黑球的比例，但我们不能把罐中的球全部拿出来数。现在我们可以每次任意从已经摇匀的罐中拿一个球出来，记录球的颜色，然后把拿出来的球 再放回罐中。这个过程可以重复，我们可以用记录的球的颜色来估计罐中黑白球的比例。假如在前面的一百次重复记录中，有七十次是白球，请问罐中白球所占的比例最有可能是多少？\n",
    "\n",
    "很多人马上就有答案了：70%。而其后的理论支撑是什么呢？\n",
    "\n",
    "我们假设罐中白球的比例是p，那么黑球的比例就是1-p。因为每抽一个球出来，在记录颜色之后，我们把抽出的球放回了罐中并摇匀，所以每次抽出来的球的颜 色服从同一独立分布。\n",
    "\n",
    "这里我们把一次抽出来球的颜色称为一次抽样。题目中在一百次抽样中，七十次是白球的,三十次为黑球事件的概率是P(样本结果|Model)。\n",
    "\n",
    "如果第一次抽象的结果记为x1,第二次抽样的结果记为x2....那么样本结果为(x1,x2.....,x100)。这样，我们可以得到如下表达式：\n",
    "\n",
    "P(样本结果|Model)\n",
    "\n",
    "　　= P(x1,x2,…,x100|Model)\n",
    "\n",
    "　　= P(x1|Mel)P(x2|M)…P(x100|M)\n",
    "\n",
    "　　= p^70(1-p)^30.\n",
    "  \n",
    "**那么问题来了，既然有无数种分布可以选择，极大似然估计应该按照什么原则去选取这个分布呢？**\n",
    "\n",
    "**答：采取的方法是让这个样本结果出现的可能性最大，也就是使得p^70(1-p)^30值最大，那么我们就可以看成是p的方程，求导即可！**\n",
    "\n",
    "那么既然事情已经发生了，为什么不让这个出现的结果的可能性最大呢？**这也就是最大似然估计的核心。**\n",
    "\n",
    "我们想办法让观察样本出现的概率最大，转换为数学问题就是使得：\n",
    "p为何值时这个函数的值最大？对p求导，并令其为0，有：\n",
    "\n",
    "  70*p^69*(1-p)^30 -p^70*30*(1-p)^29 = 0\n",
    "\n",
    "方程两边同时除以p^69*(1-p)^29,有\n",
    "\n",
    "70*(1-p) - 30*p =0\n",
    "\n",
    "p=0.7\n",
    "\n",
    "##### 极大似然估计的数学表达\n",
    "**极大似然估计是典型的频率学派观点**，它的基本思想是：**待估计参数 theta 是客观存在的**，只是未知而已，\n",
    "\n",
    "当theta_hat_mle 满足“theta=theta_hat_mle时，该组观测样本（X1, X2, ..., Xn）=（x1,x2,..., xn）更容易被观测到。”\n",
    "\n",
    "我们就说theta_hat_mle是theta的极大似然估计值。也即，估计值theta_hat_mle使得事件发生的可能性最大。\n",
    "\n",
    "https://zhuanlan.zhihu.com/p/61593112"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 贝叶斯估计\n",
    "https://zhuanlan.zhihu.com/p/61593112\n",
    "\n",
    "**贝叶斯估计是典型的贝叶斯学派观点，** 它的基本思想是：**待估计参数theta也是随机的，** 和一般随机变量没有本质区别，\n",
    "因此只能根据观测样本估计参数theta的分布。\n",
    "\n",
    "贝叶斯估计利用了贝叶斯公式，给出贝叶斯公式的数学描述\n",
    "\n",
    "    P(Bi|A) = P(Bi)*P(A|Bi) / P(A) = P(Bi)*P(A|Bi) / sigma (j=1, n) P(Bj)* P(A|Bj)\n",
    "    \n",
    "下面给出贝叶斯估计的数学描述\n",
    "\n",
    "其中，pi(theta) 为参数theta的**先验分布(prior distribution),** 表示**对参数theta的主观认识，是非样本信息。**\n",
    "pi(theta|x)为参数theta的**后验分布(posterior distribution)。**\n",
    "\n",
    "因此，**贝叶斯估计可以看作是，在假定theta服从pi(theta)的先验分布前提下，根据样本信息去校正先验分布，得到后验分布pi(theta|x)。**\n",
    "\n",
    "由于后验分布是一个条件分布，通常我们取后验分布的期望作为参数的估计值。\n",
    "\n",
    "##### 贝叶斯理论的例子\n",
    "> 一个例子， 一辆汽车（或者电瓶车）的警报响了，你通常是什么反应？有小偷？撞车了？ 不。。 你通常什么反应都没有。因为汽车警报响一响实在是太正常了！每天都要发生好多次。本来，汽车警报设置的功能是，出现了异常情况，需要人关注。然而，由于虚警实在是太多，人们渐渐不相信警报的功能了。\n",
    "\n",
    "**贝叶斯公式就是在描述，你有多大把握能相信一件证据？（how much you can trust the evidence）**\n",
    "\n",
    "> 我们假设响警报的目的就是想说汽车被砸了。把A计作“汽车被砸了”，B计作“警报响了”，带进贝叶斯公式里看。我们想求等式左边发生A|B的概率，这是在说警报响了，汽车也确实被砸了。汽车被砸引起（trigger）警报响，即B|A。但是，也有可能是汽车被小孩子皮球踢了一下、被行人碰了一下等其他原因（统统计作∼A），其他原因引起汽车警报响了，即B|∼A。那么，现在突然听见警报响了，这时汽车已经被砸了的概率是多少呢（这即是说，警报响这个证据有了，多大把握能相信它确实是在报警说汽车被砸了）？想一想，应当这样来计算。用警报响起、汽车也被砸了这事件的数量，除以响警报事件的数量（这即【式1】）。进一步展开，即警报响起、汽车也被砸了的事件的数量，除以警报响起、汽车被砸了的事件数量加上警报响起、汽车没被砸的事件数量（这即【式2】）。\n",
    "\n",
    "可能有点绕，请稍稍想一想。\n",
    "\n",
    "再思考【式2】。想让P(A|B)=1，即警报响了，汽车一定被砸了，该怎么做呢？让P(B|∼A)P(∼A)=0即可。很容易想清楚，假若让P(∼A)=0，即杜绝了汽车被球踢、被行人碰到等等其他所有情况，那自然，警报响了，只剩下一种可能——汽车被砸了。这即是提高了响警报这个证据的说服力。\n",
    "\n",
    "**从这个角度总结贝叶斯公式：做判断的时候，要考虑所有的因素。 老板骂你，不一定是你把什么工作搞砸了，可能只是他今天出门前和太太吵了一架。**\n",
    "\n",
    "再思考【式2】。观察【式2】右边的分子，P(B|A)为汽车被砸后响警报的概率。姑且仍为这是1吧。但是，若P(A)很小，即汽车被砸的概率本身就很小，则P(B|A)P(A)仍然很小，即【式2】右边分子仍然很小，P(A|B) 还是大不起来。 这里，​P(A)即是常说的先验概率，如果A的先验概率很小，就算P(B|A)较大，可能A的后验概率P(A|B)还是不会大（假设P(B|∼A)P(∼A)不变的情况下）。\n",
    "\n",
    "**从这个角度思考贝叶斯公式：一个本来就难以发生的事情，就算出现某个证据和他强烈相关，也要谨慎。证据很可能来自别的虽然不是很相关，但发生概率较高的事情。 **\n",
    "\n",
    "发现刚才写的代码编译报错，可是我今天状态特别好，这语言我也很熟悉，犯错的概率很低。因此觉得是编译器出错了。 ————别，还是先再检查下自己的代码吧。\n",
    "\n",
    "##### 最大后验估计 MAP\n",
    "在贝叶斯估计中，如果我们采用极大似然估计的思想，考虑后验分布极大化而求解theta，就变成了**最大后验估计(Maximum A Posteriori estimation， MAP)**\n",
    "\n",
    "作为贝叶斯估计的一种近似解，MAP有其存在的价值，因为贝叶斯估计中后验分布的计算往往是非常棘手的；而且，MAP并非简单地回到极大似然估计，它依然利用了来自先验的信息，这些信息无法从观测样本获得。\n",
    "\n",
    "对上述式子稍作处理，有：\n",
    "\n",
    "如果将机器学习结构风险中的正则化项对应为上式的 log（pi(theta)) ，那么带有正则化项的最大似然学习就可以被解释为MAP。当然，这并不是总是正确的，例如，有些正则化项可能不是一个概率分布的对数，还有些正则化项依赖于数据，当然也不会是一个先验概率分布。不过，MAP提供了一个直观的方法来设计复杂但可解释的正则化项，例如，更复杂的惩罚项可以通过混合高斯分布作为先验得到，而不是一个单独的高斯分布\n",
    "\n",
    "##### 共轭先验\n",
    "\n",
    "在贝叶斯估计中，如果**选取**先验分布 pi(theta)，使得后验分布 pi(theta|x) 与 pi(theta) **属于同一分布簇（即共轭分布）**，则称 pi(theta) 为似然函数 f(x|theta) 的**共轭先验**。\n",
    "\n",
    "共轭先验的选取有如下好处：\n",
    "a).符合直观，先验分布和后验分布应该是相同形式的；\n",
    "b).可以给出后验分布的解析形式；\n",
    "c).可以形成一个先验链，即现在的后验分布可以作为下一次计算的先验分布，如果形式相同，就可以形成一个链条。\n",
    "\n",
    "常见的共轭先验有：Beta分布（二项分布）、Dirichlet分布（多项分布）。\n",
    "\n",
    "很显然，共轭先验的选取很大程度上是基于数学理论的方便性，带有很强的主观色彩，而这也是饱受频率学派诟病的一点。频率学派认为，只有在先验分布有一种不依赖主观的意义，且能根据适当的理论或以往的经验决定时，才允许在统计推断中使用先验分布，否则就会丧失客观性。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
