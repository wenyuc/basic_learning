{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Diagnoal Matrix 对角矩阵\n",
    "\n",
    "设A为n阶方阵，如果满足 $a_{ij} \\neq 0， i=j; a_{ij}= 0, i\\neq j$\n",
    "称A为对角矩阵。\n",
    "\n",
    "#### Identity 单位矩阵\n",
    "设A为n阶方阵，如果满足 $a_{ij} = 1， i=j; a_{ij}= 0, i\\neq j$\n",
    "称A为单位矩阵。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transpose Matrix 转置矩阵\n",
    "\n",
    "将矩阵的行转换维同序数的列得到的一个新矩阵，叫做A的**转置矩阵，记作$A^T$**。\n",
    "\n",
    "$ A = \\left[\\begin{matrix}1 & 2 & 0 \\cr 5 &-2 &7 \\end{matrix}\\right] $\n",
    "\n",
    "$ A^T = \\left[\\begin{matrix} 1 & 5 \\cr 2 & -2 \\cr 0 & 7 \\end{matrix}\\right] $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Symmetric Matrix 对称矩阵\n",
    "\n",
    "设A为**n阶方阵**， 如果满足$A^T = A$，即 $a_{ij}=a_{ji} (i,j = 1,2,\\cdots, n)$\n",
    "称A为对称矩阵。它的元素以对角线为对称轴对应相等。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 幂等矩阵\n",
    "\n",
    "设A为**n阶方阵**， 如果满足$A^2 = A$，即 A 为幂等矩阵"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 可逆矩阵\n",
    "对矩阵A,若$\\exists B使得 BA = I $, 称A为可逆矩阵，且$ B=A^{-1}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Singular 奇异矩阵、non-singular非奇异矩阵\n",
    "当$\\mid A\\mid =0$时，称A为**奇异矩阵**，否则称为**非奇异矩阵**。\n",
    "\n",
    "A 为可逆矩阵$\\Leftarrow \\Rightarrow \\mid A\\mid \\neq 0$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Orthogonal Matrix 正交矩阵\n",
    "如果n阶矩阵A 满足$A^TA = I$, 即$A^{-1}=A^T$,那么称A为正交矩阵。\n",
    "\n",
    "https://blog.csdn.net/weixin_43233770/article/details/83039369?ops_request_misc=%257B%2522request%255Fid%2522%253A%2522162260017016780357246017%2522%252C%2522scm%2522%253A%252220140713.130102334.pc%255Fall.%2522%257D&request_id=162260017016780357246017&biz_id=0&utm_medium=distribute.pc_search_result.none-task-blog-2~all~first_rank_v2~rank_v29-4-83039369.first_rank_v2_pc_rank_v29&utm_term=%E6%AD%A3%E4%BA%A4%E7%9F%A9%E9%98%B5%E4%B8%8E%E6%AD%A3%E5%AE%9A%E7%9F%A9%E9%98%B5%E5%8C%BA%E5%88%AB&spm=1018.2226.3001.4187"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 特征分解 Eigendecomposition\n",
    "\n",
    "#### 矩阵的特征值和特征向量\n",
    "\n",
    "An **eigenvector of a square matrix A** is a non-zero vector $v$ such that:\n",
    "\n",
    "$$ Av = \\lambda v$$\n",
    "\n",
    "The scalar $\\lambda$ is known as the **eigenvalue** corresponding to this eigenvector. \n",
    "\n",
    "Suppose that a matrix $A$ has $n$ linearly independent eigenvectors ${v^{(1)}, v^{(2)},\\cdots,v^{(n)}}$, \n",
    "\n",
    "with corresponding eigenvalues ${\\lambda_1, \\lambda_2,\\cdots, \\lambda_n}$. We may concatenate all of the\n",
    "\n",
    "eigenvectors to form a matrix $V$ with one eigenvector **per column**: $V=[v^{(1)}, v^{(2)},\\cdots,v^{(n)}]$.\n",
    "\n",
    "Likewise, we can concatenate the eigenvalues to form a vector $\\lambda = [\\lambda_1, \\lambda_2,\\cdots, \\lambda_n]^T$\n",
    "\n",
    "The **特征分解 eigendecomposition of A** is then given by\n",
    "\n",
    "$$ A = V diag(\\lambda)V^{-1} $$\n",
    "\n",
    "**Not every matrix can be decomposed into eigenvalues and eigenvectors**. In some cases, the decomposition exists, but may involve complex rather than real numbers.\n",
    "\n",
    "#### 对称矩阵的特征分解\n",
    "\n",
    "**Every real symmetric matrix can be decomposed into an expression using only real-valued eigenvectors and eigenvalues**:\n",
    "\n",
    "$$ A = Q\\Lambda Q^T $$\n",
    "\n",
    "where Q is an **Orthogonal matrix 正交矩阵** composed of eigenvectors of A, and $\\Lambda$ is a **diagonal matrix 对角矩阵**.\n",
    "\n",
    "The eigenvalue $\\Lambda_{i,i}$ is associated with the eigenvector in column i of Q, denoted as $Q_{:,i}$.\n",
    "\n",
    "**任何一个对称矩阵A 都有特征分解，但特征分解并不唯一**。通常将$\\Lambda$中的数降序排列。在这种情况下，如果特征值都不相同，特征分解唯一。\n",
    "\n",
    "#### 正定、半正定、负定、半负定矩阵\n",
    "\n",
    "A matrix whose eigenvalues are all positive is called **正定矩阵positive definite matrix**. \n",
    "\n",
    "A matrix whose eigenvalues are all positive **or zero-valued** is called **半正定positive semidefinite matrix**.\n",
    "\n",
    "Likewise, if all eigenvalues are negative, the matrix is **负定矩阵negative definite**, and if all eigenvalues \n",
    "\n",
    "are negative or zero-valued, it is **半负定negative semidefinite**.\n",
    "\n",
    "Positive semidefinite matrices: $\\forall x, x^TAx \\geq 0$ \n",
    "\n",
    "Positive definite matrics additionally guarantees that $x^TAx = 0 \\Rightarrow x=0$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 奇异值分解Singular Value Decomposition \n",
    "\n",
    "参考资料：\n",
    "> https://mp.weixin.qq.com/s/I0Pb6pPYVIW02_Oxkcsfng\n",
    "\n",
    "The **singular value decomposition (SVD)** provides another way to factorize a matrix into **singular vectors** and **singular values**.\n",
    "\n",
    "The SVD allows us to discover some of the same kind of information as the **eigencomposition**. However, SVD is more generally applicable.\n",
    "\n",
    "**Every real matrix has a singular value decomposition**, but the same is not true of the eigenvalue decomposition. For example, if a matrix is not square, the eigendecomposition is not defined, and we must use a singular value decomposition instead.\n",
    "\n",
    "Suppose that A is an $m\\times n$ matrix. We will write A as a product of three matrices:\n",
    "\n",
    "$$ A = UDV$$\n",
    "\n",
    "$U$ is defined to be an $m\\times m$ matrix, $D$ is defined to be an $m\\times n$ matrix, and$V$ is defined to be an $n\\times n$ matrix.\n",
    "\n",
    "**The matrices U and V are both defined to be orthogonal matrices**. The matrix D is defined to be **a diagonal matrix. Note that D is not necessarily square**.\n",
    "\n",
    "> D 又写为Sigma, $\\Sigma$, 一个$m\\times n$ 的对角矩阵。\n",
    "“Introduction to Linear Algebra\", 2016, p371\n",
    "\n",
    "The elements along the diagonal of D are known as the **singular values** of the matrix A. The columns of U are known as the **left-singular vectors**. The columns of V are known as as the **right-singular vectors**.\n",
    "\n",
    "The left-singular vectors of A are the eigenvectors of $AA^T$. The right-singular vectors of A are the eigenvectors of $A^TA$. The non-zero singular values of A are the square roots of the eigenvalues of $A^TA$. The same is true for $AA^T$.\n",
    "\n",
    "Perhaps the most useful feature of the SVD is that we can use it to partially generalize matrix inversion to non-square matrices, as we will see in the next section？\n",
    "\n",
    "> How to understand this sentence?\n",
    "\n",
    "---\n",
    "\n",
    "SVD是通过迭代式的数值方法计算的（具体计算暂时略去）。**每一个矩形矩阵都有一个奇异值分解，尽管所得到的矩阵可能包含复数值以及浮点算术的局限性可能导致某些举行无法简单利落地完成分解**。\n",
    "\n",
    "**SVD**让我们可以发现某些与**特征分解**同类型的信息。但是,SVD又更广的适用性。\n",
    "\n",
    "**SVD**在矩阵求逆等其它矩阵计算有广泛的应用，但也可用作机器学习中的数据归约方法。SVD也可用在最小二乘线性回归，图像压缩和数据去噪中。\n",
    "\n",
    "---\n",
    "\n",
    "#### 计算奇异值分解"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2],\n",
       "       [3, 4],\n",
       "       [5, 6]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([[-0.2298477 ,  0.88346102,  0.40824829],\n",
       "       [-0.52474482,  0.24078249, -0.81649658],\n",
       "       [-0.81964194, -0.40189603,  0.40824829]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([9.52551809, 0.51430058])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([[-0.61962948, -0.78489445],\n",
       "       [-0.78489445,  0.61962948]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Singular-value decomposition\n",
    "from numpy import array\n",
    "from scipy.linalg import svd \n",
    "\n",
    "A = array([[1,2],[3,4],[5,6]])\n",
    "A \n",
    "U, s, V = svd(A)\n",
    "U\n",
    "s\n",
    "V "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 根据SVD重建矩阵\n",
    "svd()返回的U, s, V元素不能直接相乘。\n",
    "\n",
    "s向量必须使用diag()函数转换成对角矩阵。默认情况下，这个函数将创建一个相对于原来矩阵的 m x m 的方形矩阵。\n",
    "\n",
    "创建了方形的Sigma对角矩阵后，各个矩阵的大小与我们分解的原始 n x m 矩阵是相关的。\n",
    "\n",
    "$$ U (m\\times m),\\Sigma(m \\times m), V^T(n \\times n)$$\n",
    "\n",
    "而事实上，我们需要：\n",
    "\n",
    "$$ U (m\\times m),\\Sigma(m \\times n), V^T(n \\times n)$$\n",
    "\n",
    "可以通过创建一个全是0值的 m x n 的新 $\\Sigma$ 矩阵（比如，更多行）并使用通过diag()计算得到的方形对角矩阵来填充矩阵的前 n x n 部分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[1, 2],\n",
       "        [3, 4],\n",
       "        [5, 6]]),\n",
       " (3, 2))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(array([[-0.2298477 ,  0.88346102,  0.40824829],\n",
       "        [-0.52474482,  0.24078249, -0.81649658],\n",
       "        [-0.81964194, -0.40189603,  0.40824829]]),\n",
       " array([9.52551809, 0.51430058]),\n",
       " array([[-0.61962948, -0.78489445],\n",
       "        [-0.78489445,  0.61962948]]))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "((3, 3), (3, 2), (2, 2))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([[9.52551809, 0.        ],\n",
       "       [0.        , 0.51430058],\n",
       "       [0.        , 0.        ]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([[1., 2.],\n",
       "       [3., 4.],\n",
       "       [5., 6.]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reconstruct SVD\n",
    "from numpy import array, diag, dot, zeros\n",
    "# from numpy import diag\n",
    "# from numpy import dot\n",
    "# from numpy import zeros\n",
    "from scipy.linalg import svd \n",
    "\n",
    "A = array([[1,2],[3,4],[5,6]])\n",
    "A, A.shape\n",
    "# Singular-Value Decomposition\n",
    "U, s, V = svd(A)\n",
    "U, s, V\n",
    "# Create an m x n Sigma matrix\n",
    "Sigma = zeros((A.shape[0], A.shape[1]))\n",
    "# Populate Sigma with n x n diagnoal matrix\n",
    "Sigma[:A.shape[1], :A.shape[1]] = diag(s)\n",
    "# reconstruct matrix\n",
    "U.shape, Sigma.shape, V.shape\n",
    "Sigma\n",
    "B = U.dot(Sigma.dot(V))\n",
    "B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[1, 2, 3],\n",
       "        [4, 5, 6],\n",
       "        [7, 8, 9]]),\n",
       " (3, 3))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(array([[-0.21483724,  0.88723069,  0.40824829],\n",
       "        [-0.52058739,  0.24964395, -0.81649658],\n",
       "        [-0.82633754, -0.38794278,  0.40824829]]),\n",
       " array([1.68481034e+01, 1.06836951e+00, 3.33475287e-16]),\n",
       " array([[-0.47967118, -0.57236779, -0.66506441],\n",
       "        [-0.77669099, -0.07568647,  0.62531805],\n",
       "        [-0.40824829,  0.81649658, -0.40824829]]))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([[1.68481034e+01, 0.00000000e+00, 0.00000000e+00],\n",
       "       [0.00000000e+00, 1.06836951e+00, 0.00000000e+00],\n",
       "       [0.00000000e+00, 0.00000000e+00, 3.33475287e-16]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([[1., 2., 3.],\n",
       "       [4., 5., 6.],\n",
       "       [7., 8., 9.]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# square matrix\n",
    "from numpy import array, diag, dot, zeros\n",
    "# from numpy import diag\n",
    "# from numpy import dot\n",
    "# from numpy import zeros\n",
    "from scipy.linalg import svd \n",
    "\n",
    "A = array([[1,2,3],[4,5,6],[7,8,9]])\n",
    "A, A.shape\n",
    "# Singular-Value Decomposition\n",
    "U, s, V = svd(A)\n",
    "U, s, V\n",
    "# Create an m x n Sigma matrix\n",
    "Sigma = diag(s)\n",
    "Sigma\n",
    "# reconstruct matrix\n",
    "B = U.dot(Sigma.dot(V))\n",
    "B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 用于伪逆的SVD\n",
    "\n",
    "伪逆(pseudoinverse)是将方形矩阵的矩形求逆泛化应用到行数和列数不等的矩形矩阵上。这也被称为广义逆(Generalized inverse) 或摩尔-彭若斯逆(Moore-Penrose Inverse)。\n",
    "\n",
    "伪逆表示为$A^+$\n",
    "\n",
    "伪逆式使用A的奇异值分解计算的\n",
    "\n",
    "$$A^+ = V\\cdot D^+ \\cdot U^T$$\n",
    "\n",
    "其中，$A^+$是A的**伪逆**，$D^+$是对角矩阵Sigma的**伪逆**，$U^T$是U的**转置**。\n",
    "\n",
    "> 可以根据svd运算得到U和V。\n",
    "> 根据Sigma创建一个对角矩阵，计算Sigma中每个非零元素的倒数，就可以得到$D^+$,如下：\n",
    ">\n",
    "$ Sigma = \\left[\\begin{matrix} s11 & 0 & 0 \\cr 0 & s22 & 0 \\cr 0 & 0 & s33 \\end{matrix}\\right] $\n",
    ">\n",
    "$D^+ =$ $ \\left[\\begin{matrix} \\cfrac{1}{s11} & 0 & 0 \\cr 0 & \\cfrac{1}{s22} & 0 \\cr 0 & 0 & \\cfrac{1}{s33} \\end{matrix}\\right] $\n",
    "\n",
    "伪逆提供了一种求解线性回归方程的方法，尤其是当**行数多于列数**时，而这也是很常见的情况。\n",
    "\n",
    "Numpy提供了函数pinv()来计算矩形的伪逆。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2],\n",
       "       [3, 4],\n",
       "       [5, 6],\n",
       "       [7, 8]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([[-1.00000000e+00, -5.00000000e-01,  8.64905778e-17,\n",
       "         5.00000000e-01],\n",
       "       [ 8.50000000e-01,  4.50000000e-01,  5.00000000e-02,\n",
       "        -3.50000000e-01]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#pseudoinverse\n",
    "from numpy import array\n",
    "from scipy.linalg import pinv\n",
    "#define array\n",
    "A = array([[1,2],[3,4],[5,6],[7,8]])\n",
    "A \n",
    "#calculate pseudoinverse\n",
    "B = pinv(A)\n",
    "B "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以通过svd采用人工的方式计算伪逆，并将结果与pinv()函数的结果进行比较。\n",
    "具体实现方式为：\n",
    "$$ A^+ = V^T \\cdot D^T \\cdot U^T$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2],\n",
       "       [3, 4],\n",
       "       [5, 6],\n",
       "       [7, 8]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([[-1.00000000e+00, -5.00000000e-01,  2.20397652e-17,\n",
       "         5.00000000e-01],\n",
       "       [ 8.50000000e-01,  4.50000000e-01,  5.00000000e-02,\n",
       "        -3.50000000e-01]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#pseudoinverse through svd\n",
    "from numpy import array, zeros, diag \n",
    "from scipy.linalg import svd \n",
    "#define matrix\n",
    "A = array([[1,2],[3,4],[5,6],[7,8]])\n",
    "A \n",
    "#calculate svd\n",
    "U,s,V = svd(A)\n",
    "#reciprocals of s\n",
    "d = 1.0 / s\n",
    "#create mxn matrix\n",
    "D = zeros(A.shape)\n",
    "#populate D with nxn diagonal matrix\n",
    "D[:A.shape[1], :A.shape[1]] = diag(d)\n",
    "#calculate pseudoinverse\n",
    "B = V.T.dot(D.T).dot(U.T)\n",
    "B "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 用于降维的svd\n",
    "\n",
    "SVD的一大常见应用是降维。\n",
    "\n",
    "具有大量特征的数据（比如特征数（列数）多于观察数（行数））也许可以被**归约**成与所涉预测问题最相关的**更小特征子集**。\n",
    "\n",
    "其结果是一个秩更低的矩阵，<u>据说接近原始矩阵</u>。不知道这个“据说”是什么意思。\n",
    "\n",
    "为了做到这一点，我们可以在原来的数据上执行一次 SVD 操作并**选择 Sigma 中前 k 个最大的奇异值**。这些**列可以从 Sigma 中选择得到，行可以从 $V^T$ 中选择得到**。\n",
    "\n",
    "然后可以重建原始向量 A 的近似 B。\n",
    "\n",
    "$ B = U \\cdot Sigma(k) \\cdot V^T(k)$\n",
    "\n",
    "---\n",
    "\n",
    "在自然语言处理中，这种方法可以被用在文档中词出现情况或词频的矩阵上，并被称为**隐含语义分析（Latent Semantic Analysis）或隐含语义索引（Latent Semantic Indexing）**。\n",
    "\n",
    "在实践中，我们可以保留和使用被称为 T 的**描述性数据子集。这是矩阵的密集总结或投射**。\n",
    "\n",
    "$T=U\\cdot Sigma(k)$\n",
    "\n",
    "此外，这种变换既可以在原来的矩阵 A 上计算和应用，也可以在其它类似的矩阵上计算和应用。\n",
    "\n",
    "$T=V^T(k) \\cdot A$\n",
    "\n",
    "---\n",
    "\n",
    "下面的示例是使用 SVD 的数据归约。\n",
    "\n",
    "首先定义一个 3×10 的矩阵，其列数多于行数。然后计算 SVD 并且只选取其前两个特征。这些元素再重新结合起来，得到原始矩阵的准确再现。最后计算转换的方式有两种。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3, 3), (3,), (10, 10))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([[ 2.57279362,  3.35440288,  4.13601214,  3.43636548,  4.21797474,\n",
       "         4.999584  ,  7.26244918,  8.04405844,  8.8256677 ,  9.60727696],\n",
       "       [ 9.62974585, 10.82001291, 12.01027997, 14.49105142, 15.68131848,\n",
       "        16.87158554, 16.77134821, 17.96161527, 19.15188233, 20.34214939],\n",
       "       [21.4269724 , 22.36768502, 23.30839763, 33.84698794, 34.78770056,\n",
       "        35.72841318, 27.0712481 , 28.01196072, 28.95267333, 29.89338595]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([[-18.20721501,  -6.76115284],\n",
       "       [-49.39240188,  -6.28349004],\n",
       "       [-91.44373766,   4.74016526]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([[-18.20721501,  -6.76115284],\n",
       "       [-49.39240188,  -6.28349004],\n",
       "       [-91.44373766,   4.74016526]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from numpy import array, diag, zeros\n",
    "from scipy.linalg import svd\n",
    "# create matrix, #column > # row\n",
    "A = array([[1,2,3,4,5,6,7,8,9,10],\n",
    "             [11,12,13,14,15,16,17,18,19,20],\n",
    "             [21,22,23,34,35,36,27,28,29,30]])\n",
    "# svd\n",
    "U,s,V = svd(A)\n",
    "U.shape,s.shape,V.shape \n",
    "#create a mxn Sigma matrix\n",
    "Sigma = zeros(A.shape)\n",
    "#populate Sigma with nxn diagonal matrix\n",
    "Sigma[:A.shape[0], :A.shape[0]] = diag(s)\n",
    "#select\n",
    "n_elements = 2\n",
    "Sigma = Sigma[:, :n_elements]\n",
    "V = V[:n_elements,:]\n",
    "#reconstruct\n",
    "B = U.dot(Sigma.dot(V))\n",
    "B\n",
    "#transform\n",
    "T = U.dot(Sigma)\n",
    "T\n",
    "T = A.dot(V.T)\n",
    "T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "scikit-learn 提供了直接实现这种功能的 TruncatedSVD 类。\n",
    "\n",
    "TruncatedSVD 的创建必须指定所需的特征数或所要选择的成分数，比如 2。一旦创建完成，你就可以通过调用 fit() 函数来拟合该变换（比如：计算 $V^T(k)$），然后再通过调用 transform() 函数将其应用于原始矩阵。结果得到上面被称为 T 的 A 的变换。\n",
    "\n",
    "下面的示例演示了 TruncatedSVD 类。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TruncatedSVD()"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([[18.20721501,  6.76115284],\n",
       "       [49.39240188,  6.28349004],\n",
       "       [91.44373766, -4.74016526]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from numpy import array\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "# create matrix, #column > # row\n",
    "A = array([[1,2,3,4,5,6,7,8,9,10],\n",
    "             [11,12,13,14,15,16,17,18,19,20],\n",
    "             [21,22,23,34,35,36,27,28,29,30]])\n",
    "#svd\n",
    "svd = TruncatedSVD(n_components=2)\n",
    "svd.fit(A)\n",
    "result = svd.transform(A)\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以看到，结果得到的值与上面人工计算的结果一致，**但某些值的符号不一样**。由于所涉及的计算的性质以及所用的基础库和方法的差异，可以预见在符号方面会存在一些不稳定性。只要对该变换进行训练以便复用，这种不稳定性在实践中应该不成问题。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
