{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The basic steps to implement Linear Regression\n",
    "1. Import the packages and classes you need;\n",
    "2. Provide data to work with and eventually do appropriate cleaning.\n",
    "3. Create a regression model and fit it with existing data;\n",
    "4. Check the results of model fitting to know whether the model is satisfactory;\n",
    "5. Apply the model for predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### I. Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 1 import the packages and classes\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 5],\n",
       "       [15],\n",
       "       [25],\n",
       "       [35],\n",
       "       [45],\n",
       "       [55]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([ 5, 20, 14, 32, 22, 38])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# step 2 provide the data\n",
    "# array.reshape(-1, 1) is to make the array two-dimensional,\n",
    "# to have one column and as many rows as necesary.\n",
    "x = np.array([5, 15, 25, 35, 45, 55]).reshape(-1, 1)\n",
    "y = np.array([5, 20, 14, 32, 22, 38])\n",
    "display(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6, 1)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6,)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape    # y has a single dimension, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 3 create a model and fit it\n",
    "model = LinearRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LinearRegression provides several optional prarmeters to optimize\n",
    "1. fit_intercept is a Boolean (True by default) to decide whether to calculate the intercept b0 (True) or consider it equal to zero(False).\n",
    "2. normalize is a Boolean (False by default) to decide whether to normalize the input variables (True) or not (False).\n",
    "3. copy_x is a Boolean (True by default) to decide whether to copy (True) or overwrite the input variables (False).\n",
    "4. n_jobs is an integer or None (default) to represent the # of jobs used in parallel computation. None = one job, -1 = to use all processes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use default values of all parameters\n",
    "# to start using the model.\n",
    "# to calculate the optimal values of weights b0 and b1\n",
    "# using the existing input and output (x and y) as the arguments.\n",
    "model.fit(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.715875613747954"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# step 4 get results\n",
    "# the arguments of .score() are also the predictor x and regresson y,\n",
    "# and the return value is R^2\n",
    "r_sq = model.score(x, y)\n",
    "r_sq        # coefficient of determination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.633333333333329"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.intercept_    # represents the coefficient, b0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.54])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.coef_        # represents the b1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5.63333333, 6.17333333, 6.71333333, 7.25333333, 7.79333333])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# step 5 predict\n",
    "x_new = np.arange(5).reshape(-1, 1)\n",
    "y_new = model.predict(x_new)\n",
    "y_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### II. Multiple Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 1\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  1],\n",
       "       [ 5,  1],\n",
       "       [15,  2],\n",
       "       [25,  5],\n",
       "       [35, 11],\n",
       "       [45, 15],\n",
       "       [55, 34],\n",
       "       [60, 35]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([ 4,  5, 20, 14, 32, 22, 38, 43])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# step 2\n",
    "x = [[0, 1], [5, 1], [15, 2], [25, 5], [35, 11], [45, 15], [55, 34], [60, 35]]\n",
    "y = [4, 5, 20, 14, 32, 22, 38, 43]\n",
    "x, y = np.array(x), np.array(y)\n",
    "display(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# step 3\n",
    "model2 = LinearRegression()\n",
    "model2.fit(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8615939258756776"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# step 4\n",
    "r_sq = model2. score(x, y)\n",
    "r_sq          # coefficient of determination\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.52257927519819"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([0.44706965, 0.25502548])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(model2. intercept_, model2.coef_)   # intercept and coefficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 5.77760476,  8.012953  , 12.73867497, 17.9744479 , 23.97529728,\n",
       "       29.4660957 , 38.78227633, 41.27265006])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# step 5\n",
    "y_pred = model2.predict(x)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 5.77760476,  8.012953  , 12.73867497, 17.9744479 , 23.97529728,\n",
       "       29.4660957 , 38.78227633, 41.27265006])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model2.intercept_ + np.sum(model2.coef_ * x, axis = 1)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1],\n",
       "       [2, 3],\n",
       "       [4, 5],\n",
       "       [6, 7],\n",
       "       [8, 9]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predict new value\n",
    "x_new = np.arange(10).reshape((-1, 2))\n",
    "x_new\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 5.77760476],\n",
       "       [ 7.18179502],\n",
       "       [ 8.58598528],\n",
       "       [ 9.99017554],\n",
       "       [11.3943658 ]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_new = model2.predict(x_new)\n",
    "y_new.reshape((-1,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### III. Polynomial Regression \n",
    "There is only one extra step: to transform the array of inputs to include non-linear terms such as x^2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 1\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 5],\n",
       "       [15],\n",
       "       [25],\n",
       "       [35],\n",
       "       [45],\n",
       "       [55]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([15, 11,  2,  8, 25, 32])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# step 2a provide data\n",
    "x = np.array([5, 15, 25, 35, 45, 55]).reshape((-1, 1))\n",
    "y = np.array([15, 11, 2, 8, 25, 32])\n",
    "display(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 2b transform input data\n",
    "transformer = PolynomialFeatures(degree = 2, include_bias = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PolynomialFeatures provide several parameters:\n",
    "1. degree is an integer (2 by default) that provides the degree of the polynomial regression function.\n",
    "2. interaction_only is a Boolean (False by default) that decides whether to include only interaction features (True) or all features (False).\n",
    "3. include_bias is a Boolean (True by default) that decides whether to include bias (intercept) column of ones (True) or not (False).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   5.,   25.],\n",
       "       [  15.,  225.],\n",
       "       [  25.,  625.],\n",
       "       [  35., 1225.],\n",
       "       [  45., 2025.],\n",
       "       [  55., 3025.]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# before applying transformer, you need to fit it\n",
    "transformer.fit(x)\n",
    "\n",
    "# once transformer is fitted, it's ready to create a new , modified input\n",
    "# .transform() takes the input array as the argument and returns the modified array.\n",
    "x_ = transformer.transform(x)\n",
    "x_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# step 3 create a model and fit it\n",
    "model3 = LinearRegression()\n",
    "model3.fit(x_, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8908516262498564"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# step 4 get results\n",
    "r_sq = model3.score(x_, y)\n",
    "r_sq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21.372321428571425"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([-1.32357143,  0.02839286])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(model3.intercept_, model3.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### New transformation and regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.000e+00, 5.000e+00, 2.500e+01],\n",
       "       [1.000e+00, 1.500e+01, 2.250e+02],\n",
       "       [1.000e+00, 2.500e+01, 6.250e+02],\n",
       "       [1.000e+00, 3.500e+01, 1.225e+03],\n",
       "       [1.000e+00, 4.500e+01, 2.025e+03],\n",
       "       [1.000e+00, 5.500e+01, 3.025e+03]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# new step 2b, different transformation and regression arguments\n",
    "x_ = PolynomialFeatures(degree = 2, include_bias = True).fit_transform(x)\n",
    "x_\n",
    "# to obtain the new input array x_ with the additional leftmost column \n",
    "# containing only ones. This column corresponds to the intercept."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 3 The intercept is already included with the leftmost\n",
    "# column of ones, and don't need to include it again when \n",
    "# creating the instance of LinearRegression.\n",
    "model4 = LinearRegression(fit_intercept = False).fit(x_, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8908516262498565"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# step 4\n",
    "r_sq = model4.score(x_, y)\n",
    "r_sq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model4. intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([21.37232143, -1.32357143,  0.02839286])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model4.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([15.46428571,  7.90714286,  6.02857143,  9.82857143, 19.30714286,\n",
       "       34.46428571])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# step 5\n",
    "y_pred = model4.predict(x_)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### An example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9453701449127822"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.8430556452395734"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([ 2.44828275,  0.16160353, -0.15259677,  0.47928683, -0.4641851 ])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.54047408, 11.36340283, 16.07809622, 15.79139   , 29.73858619,\n",
       "       23.50834636, 39.05631386, 41.92339046])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Step 1: Import packages\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "# Step 2a: Provide data\n",
    "x = [[0, 1], [5, 1], [15, 2], [25, 5], [35, 11], [45, 15], [55, 34], [60, 35]]\n",
    "y = [4, 5, 20, 14, 32, 22, 38, 43]\n",
    "x, y = np.array(x), np.array(y)\n",
    "\n",
    "# Step 2b: Transform input data\n",
    "x_ = PolynomialFeatures(degree=2, include_bias=False).fit_transform(x)\n",
    "\n",
    "# Step 3: Create a model and fit it\n",
    "model5 = LinearRegression().fit(x_, y)\n",
    "\n",
    "# Step 4: Get Results\n",
    "r_sq = model5.score(x_, y)\n",
    "intercept, coefficients = model5. intercept_, model5.coef_\n",
    "display(r_sq, intercept, coefficients)\n",
    "\n",
    "# Step 5: Predict\n",
    "y_pred = model5.predict(x_)\n",
    "display(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### There are six coefficients (including the intercept) for regression function\n",
    "ùëì(ùë•‚ÇÅ, ùë•‚ÇÇ) = ùëè‚ÇÄ + ùëè‚ÇÅùë•‚ÇÅ + ùëè‚ÇÇùë•‚ÇÇ + ùëè‚ÇÉùë•‚ÇÅ¬≤ + ùëè‚ÇÑùë•‚ÇÅùë•‚ÇÇ + ùëè‚ÇÖùë•‚ÇÇ¬≤."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### IV. Advanced LinearRegressoin with statsmodels package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 1\n",
    "import numpy as np\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 0,  1],\n",
       "        [ 5,  1],\n",
       "        [15,  2],\n",
       "        [25,  5],\n",
       "        [35, 11],\n",
       "        [45, 15],\n",
       "        [55, 34],\n",
       "        [60, 35]]), array([ 4,  5, 20, 14, 32, 22, 38, 43]))"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# step 2a\n",
    "x = [[0, 1], [5, 1], [15, 2], [25, 5], [35, 11], [45, 15], [55, 34], [60, 35]]\n",
    "y = [4, 5, 20, 14, 32, 22, 38, 43]\n",
    "x, y = np.array(x), np.array(y)\n",
    "x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  0.,  1.],\n",
       "       [ 1.,  5.,  1.],\n",
       "       [ 1., 15.,  2.],\n",
       "       [ 1., 25.,  5.],\n",
       "       [ 1., 35., 11.],\n",
       "       [ 1., 45., 15.],\n",
       "       [ 1., 55., 34.],\n",
       "       [ 1., 60., 35.]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([ 4,  5, 20, 14, 32, 22, 38, 43])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# step 2b: to add the column of ones to the inputs if you want statmodels \n",
    "# to calculate the intercept b0. \n",
    "x = sm.add_constant(x)\n",
    "display(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 3: the regression model based on Ordinary Least Squares is \n",
    "# an instance of the class statmodels.regression.linear_model.OLS\n",
    "model6 = sm.OLS(y, x)\n",
    "results = model6.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.862</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.806</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   15.56</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sun, 26 Apr 2020</td> <th>  Prob (F-statistic):</th>  <td>0.00713</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>15:08:35</td>     <th>  Log-Likelihood:    </th> <td> -24.316</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>     8</td>      <th>  AIC:               </th> <td>   54.63</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>     5</td>      <th>  BIC:               </th> <td>   54.87</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     2</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>    5.5226</td> <td>    4.431</td> <td>    1.246</td> <td> 0.268</td> <td>   -5.867</td> <td>   16.912</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>    0.4471</td> <td>    0.285</td> <td>    1.567</td> <td> 0.178</td> <td>   -0.286</td> <td>    1.180</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>    <td>    0.2550</td> <td>    0.453</td> <td>    0.563</td> <td> 0.598</td> <td>   -0.910</td> <td>    1.420</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 0.561</td> <th>  Durbin-Watson:     </th> <td>   3.268</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.755</td> <th>  Jarque-Bera (JB):  </th> <td>   0.534</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.380</td> <th>  Prob(JB):          </th> <td>   0.766</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 1.987</td> <th>  Cond. No.          </th> <td>    80.1</td>\n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.862\n",
       "Model:                            OLS   Adj. R-squared:                  0.806\n",
       "Method:                 Least Squares   F-statistic:                     15.56\n",
       "Date:                Sun, 26 Apr 2020   Prob (F-statistic):            0.00713\n",
       "Time:                        15:08:35   Log-Likelihood:                -24.316\n",
       "No. Observations:                   8   AIC:                             54.63\n",
       "Df Residuals:                       5   BIC:                             54.87\n",
       "Df Model:                           2                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const          5.5226      4.431      1.246      0.268      -5.867      16.912\n",
       "x1             0.4471      0.285      1.567      0.178      -0.286       1.180\n",
       "x2             0.2550      0.453      0.563      0.598      -0.910       1.420\n",
       "==============================================================================\n",
       "Omnibus:                        0.561   Durbin-Watson:                   3.268\n",
       "Prob(Omnibus):                  0.755   Jarque-Bera (JB):                0.534\n",
       "Skew:                           0.380   Prob(JB):                        0.766\n",
       "Kurtosis:                       1.987   Cond. No.                         80.1\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# step 4 get results\n",
    "display(results.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8615939258756777"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_sq = results.rsquared     # coefficient of determination\n",
    "r_sq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8062314962259488"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_sq_adj = results.rsquared_adj    # adjusted coefficient of determination.\n",
    "r_sq_adj    # R^2 corrected according to the # of input features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5.52257928, 0.44706965, 0.25502548])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_coef = results.params    # regression coefficients, refers the array with b0, b1, b2 respectively\n",
    "reg_coef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 1.],\n",
       "       [1., 2., 3.],\n",
       "       [1., 4., 5.],\n",
       "       [1., 6., 7.],\n",
       "       [1., 8., 9.]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([ 5.77760476,  7.18179502,  8.58598528,  9.99017554, 11.3943658 ])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# step 5: predict\n",
    "x_new = sm.add_constant(np.arange(10).reshape((-1, 2)))\n",
    "y_new = results.predict(x_new)\n",
    "display(x_new, y_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Linear Regression is sometimes not appropriate, especially for non-linear models of high complexity.\n",
    "\n",
    "Fortunately, there are other regression techniques suitable for the cases where linear regression doesn‚Äôt work well. Some of them are support vector machines, decision trees, random forest, and neural networks.\n",
    "\n",
    "The package scikit-learn provides the means for using other regression techniques in a very similar way to what you‚Äôve seen. It contains the classes for support vector machines, decision trees, random forest, and more, with the methods .fit(), .predict(), .score() and so on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
